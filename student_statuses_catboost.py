# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u_r3uHtGBFWwfdztqUF12DwIDMoWUfJF
"""

from google.colab import files


uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import tree
from sklearn.metrics import f1_score

data = pd.read_csv('train_dataset_train.csv')
data.head(10)

data.info()

data.describe(include = 'all')

data = data.fillna(0)

data['Статус'].value_counts()

sns.pairplot(data, kind="scatter")

plt.rcParams['figure.figsize']=(15,15)


data_corr = list(set(data.columns.values) - set(['Опекунство','Пособие']))
g = sns.heatmap(data[data_corr].corr(), square = True, annot=True, robust=True)

sns.countplot(x="Статус", data=data).set_title('Распределение предсказываемой величины')

data.dtypes[data.dtypes == "object"].index.values

# Удаление всех категориальных данных
mass_object = data.dtypes[data.dtypes == "object"].index.values
mass_object = np.append(mass_object, "Статус")

X = data.drop(mass_object, axis = 1)
y = data[["Статус"]]

names = list(data.columns[data.dtypes=='object'])

for name in names:
  ind = list(pd.unique(data[name]))
  data[name] = data[name].apply(lambda x: ind.index(x))

X = data.drop(["Статус", ], axis = 1)
y = data[["Статус"]]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""# RandomForest"""

model = RandomForestClassifier(n_estimators = 250,random_state=0, bootstrap = True)

model.fit(X_train, y_train)

pred = model.predict(X_test)

y_test.head(3)

f1_score(y_test, pred, average='macro', zero_division = 0)

"""# CatBoostClassifier"""

from catboost import CatBoostClassifier, Pool, metrics, cv
from sklearn.metrics import accuracy_score

model_1 = CatBoostClassifier(iterations=1000,
                          learning_rate=0.04,
                          depth=5, random_seed=42, logging_level='Silent',
                          )
# Fit model
model_1.fit(X_train, y_train)
# Get predictions
pred_cl = model_1.predict(X_test, verbose=False)
# custom_loss=[metrics.Accuracy()]

f1_score(y_test, pred_cl, average='macro', zero_division = 0)

"""# работа с тестовой выборкой - новый набор данных для модели"""

from google.colab import files


uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

test = pd.read_csv('test_dataset_test.csv')
test.head(10)

test_object = test.dtypes[test.dtypes == "object"].index.values
test = test.drop(mass_object, axis = 1)

"""# оставляем категориальные данные"""

names = list(test.columns[test.dtypes=='object'])

for name in names:
  ind = list(pd.unique(test[name]))
  test[name] = test[name].apply(lambda x: ind.index(x))

test = test.fillna(0)

"""# предсказания"""

rf_predictions = model_1.predict(test)

# rf_probs = model_new.predict_proba(test)[:, 1]

pred = model_1.predict(test)
print(pred)

"""# Сохранение данных"""

df_submission = {'Статус': [pred]}

pred = pd.DataFrame(pred)
pred.head(10)

pred['ID'] = test['ID']
pred.head(10)

pred.rename(columns = {0 : 'Статус'}, inplace = True)
pred.head(104)

pred = pred.reindex(columns=['ID', 'Статус'])
pred.head(10)

pred.to_csv("df_submission.csv", index=False)
files.download('df_submission.csv')